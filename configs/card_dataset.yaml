
num_workers: 0
batch_size: 6

cardDataset:
  root: './data'
  raw: 'AllPrintings.json'
  db: 'AllCards.json'

  features: ['name', 'ctype', 'text', 'manaCost', 'toughness', 'power']
  tokenizer: "EleutherAI/gpt-neo-125M" # 'EleutherAI/gpt-neo-1.3B'
  max_tokens_card: 60 # Used to reduce cards
  context_window: 2048

  token_ids:
    additional_special_tokens: ['[CLONE]', '[MASK]', '[SEP]']
    pad_token: '[PAD]'
 
  summarize_model:
    chatai_parms: 
      model_name: "gpt-3.5-turbo-0613"
      temperature: 0
      max_tokens: 1000
    
    pre_prompt: "./dataset/summarize_prompt.txt"


deckDataset:
  root: './data'
  json_name: 'AllDecks.npy'
  deck_lengths: 60
  mask_percent: 0.04
  context_window: 2048

model:
  name: "EleutherAI/gpt-neo-125M"

optimizer:
  lr: &blr 1.0e-6
  weight_decay: 0.05

coeff_step_size_up: 0.75
coeff_step_size_down: 19

schedular:
  base_lr: *blr
  max_lr: 1.0e-4
  mode: 'triangular2'
  
  cycle_momentum: false

Resume:
  chk_ptn: ''